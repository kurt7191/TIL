# GAN, 오토인코더



GAN(Generative Adversarial Network), 줄여서 GAN(간) 이라고 부름

한국말론, "생성적 적대 신경망" 이라고 칭함.



GAN 알고리즘 내부에서는 적대적인 경합이 진행된다.

이를 비유하자면

위조 지폐범과, 이를 가려내기 위해 노력하는 경찰의 관계를 비유로 들 수 있다.

위조 지폐범은 진짜 지폐와 똑같은 지폐를 만들어낼 것이고 경찰은 이를 실제 지폐와 비교하여 가짜와 진짜를 구별할 것이다. 

이 둘의 계속된 경합이 점점 더 위조 지폐범이 진짜와 가까운 위조 지폐를 만들 수 있게 돕는다는 원리이다.

페이스북은 GAN 에서 Deep Covolutional GAN 을 개발했는데 이는 GAN 의 엄청난 발전을 도왔고, 이를 DCGAN 이라고 부른다.



<HR>



## 생성자



생성자(Generator) 는 가상의 이미지를 만들어 내는 공장이다.

맨 처음에는 랜덤한 픽셀 값으로 채워진 이미지를 만들고 그 이후에 판별자의 판별 결과에 따라서 지속적으로 

업데이트 하면서 진짜와 가까운 이미지가 완성된다.



DCGAN 은 합성곱을 사용한다고 했는데, 여기서 사용하는 합성곱은 앞서 설명했던 합성곱과 조금 차이가 있다.

우선 최적화 과정이 존재하지 않고(optimizer), 컴파일 과정이 없다.

일부 매개변수를 삭제하는 풀링 과정도 없으며 대신 패딩 과정이 포함되어있다.



패딩 과정이 있는 이유는, 입력 크기와 출력 크기를 맞추기 위함임.

먼저 합성곱 과정을 거치면 연산이 되면서 데이터의 크기가 줄어듬을 우리는 알고 있다.

**생성자가 가짜 이미지를 만들 때 중요한 점은 둘의 크기가 같아야 하는데, 합성곱을 사용하면 데이터의 크기가 달라진다. 따라서 패딩을 이용하여 이미지의 크기를 동일하게 맞추어준다.**



`padding = same` 을 통해서 입력과 출력의 크기가 다를 경우 자동으로 크기를 확장, 확장된 공간에 0을 집어 넣을 수 있다.



<hr>

##### **배치 정규화(Batch Normalizationn)**



패딩 이외에 DCGAN 에서 알아두어야 할, **배치 정규화(Batch Normalizationn)**.



배치 정규화란 입력 데이터의 평균이 0, 분산이 1이 되도록 재배치하는 것.

이는 다음 층으로 입력될 값을 일정하게 재배치하는 역할을 한다.



<hr>

**생정자의 활성화 함수**



생성자의 활성화 함수로는 `ReLU()` 함수를 사용한다.

판별자로 넘겨주기 전에는 tanh() 함수를 사용한다.

탄젠트 함수는 출력되는 값을 -1과 1사이로 배정한다.



기존 relu가 아니가 LeakyReLU 를 사용



<HR>

## 판별자



생성자가 만든 이미지가 진짜인지 가짜인지 판별하는 판별자는

기존의 CONV 신경망 구조대로 만들면 된다.

왜냐하면 합성곱 신경망 구조 자체가 무엇인가를 구별하는데 사용하는데 최적화 되어있기 대문에.



주의할 점은 판별자는 진짜인지 가짜인지만 판별하지 본인이 직접 학습하면 안된다.

따라서 판별자를 만들 때는 가중치를 저장하는 학습 기능을 꺼줘야 한다.



<hr>

## 적대적 신경망 실행하기



생성자와 판별자를 연결시키고 학습을 진행, 기타 여러 가지 옵션을 설정하는 순서



생성자에서 나온 출력을 판별자에 넣어서 진위여부를 판별하게 만든다는 뜻.



생성자를 G()

판별자를 D()

실제 데이터를 X

입력값을 input



입력값을 받아들인 생성자의 출력 : G(input)

이를 받아들인 판별자 : D(G(input))



판별자는 실제 데이터를 넣은 D(X) 만을 참으로 여긴다.

하지만 G(input) 이 점점 X 와 닮아지면서 판별자가 더는 구별을 잘 못하게 되고

정확도가 0.5로 가까워질ㅈ 때 학습을 멈춘다.



다시 공부











