# 딥러닝의 동작 원리(1)



> 선형 회귀
>
> 경사 하강법



<hr>

## 선형 회귀



딥러닝의 가장 기초적인 계산 단위 두 가지 :  `선형 회귀`, `로지스틱 회귀`



기존의 데이터를 이용해서 하나의 직선을 그리고 이 직선을 이용해서 새로운 데이터에 대해 예측을 시도.

직선의 방향을 정하고 정확한 기울기와 절편을 구하면 됨.



##### 최소 제곱법 



기울기와 절편을 구할 때 사용, 단 한 개의 x가 주어졌을 때 가능.



`a = (x - x평균)(y - y평균)의 합 / (x - x평균)^2 의 합` 

`b = y의 평균 - (x의 평균 x 기울기 a)` 



이를 통해서 구한 직선이 오차가 가장 적은 예측 직선





```python
import numpy as np

x = [2,4,6,8]
y = [81,93,91,97]

mx =  np.mean(x)
my = np.mean(y)

divisor = sum([(i - mx) ** 2 for i in x])
divisor

def top(x, mx, y, my):
    d = 0
    for i in range(len(x)):
        d += (x[i] - mx) * (y[i] - my)
    return d

dividend = top(x,mx,y,my)

a = dividend / divisor
b = my - (mx * a)
```



##### 평균 제곱 오차



실상은 변수가 한 개인 것 보다 변수가 여러 개인 경우가 많다. 따라서 `최소 제곱법` 이외의 방식이 필요하다. 예측 선의 실제 데이터와의 오차가 최소가 되어야 하는데, 최소가 되게끔 하는 알고리즘인 `평균제곱오차(mse)` 를 살펴볼 것



먼저 변수가 여러 개일 때, 가설을 하나 세워서 임의의 선을 만든다. 그리고 조금씩 수정해 나간다.(오차가 최소가 될 때 까지)



즉, 예측 선을 계속 해서 개선해 나가는데 그 척도로 실제 데이터와의 `오차` 가 사용된다.



`오차 = (예측값 - 실제값)`



하지만 오차를 모두 더하면 0이 될 수 있음.

0이 되는 걸 방지하기 위해서 제곱한다. `오차의 합 = (예측값 - 실제값)^2`



이를 n으로 나누면 `평균제곱오차`  나온다.



> 선형회귀란, 데이터에 대한 임의의 직선을 구하고 이에 대한 오차를 구한 이후, 이 오차를 개선할(가장 작게 할) 새로운 직선을 찾는 것(a, b를 찾는 것)



<hr>

## 경사 하강법



기울기 a를 무한대로 키우면 오차도 무한대로 커지고 기울기 a를 무한대로 작게 해도 오차가 무한대로 커지다. 즉, 오차는 이차 방정식의 모습을 가지고 있다. 이차 방정식에서 y가 가장 적은 곳은 곡선의 꼭짓점이다.



이렇듯 이차 방정식 안에서 오차를 최소화하는 곳으로 이동하는 방식을 경사 하강법.



이차 방정식의 최솟값은 꼭짓점 m, 꼭짓점 m에서의 순간 기울기를 구해야함. 이 때의 순간 기울기는 0

즉, 미분해서 0이 되는 지점을 찾아야 한다.



이차 방정식 그래프 내에서 오른쪽 왼쪽으로 와리가리 털면서 계속 기울기가 0이되는 지점으로 이동.



##### 학습률



`learning rate`



순간 기울기, 즉 미분의 값이 0 이 되는 지점을 찾을 때, 오른쪽 왼쪽으로 와리가리 털면서 구하게 되는데, 오른쪽 왼쪽으로 갈 때의 거리를 정해야 한다. 



너무 멀게 정하면 제대로 못구할 수 있다.





<hr>

## 정리



데이터의 값을 예측하기 위해서 임의의 선 y = ax + b 만듬

선형 회귀란 실제 데이터와 예측한 데이터 간의 오차를 최소화 하는 예측선(a,b)를 구하는 과정임.

이 오차의 단위는 평균제곱오차(mse).

기울기나 y절편이나 양이나 음으로 무한대로 커질 때, 오차도 무한대로 커진다. 따라서 이차 방정식.

앞서 평균제곱오차 식에 예측선 y=ax + b 를 대입하고 이를 각각 기울기와 절편에 대해서 편미분하여 최적의 기울기와 절편을 구함.



평균제곱오차아 경사 하강법을 통해서 최적의 직선을 구할 수 있다.



<hr>

## 다중 선형 회귀



세상은 단일 변수로 설명할 수 없다. 다양한 변수들이 필요하다.



이 때 앞서 배운 경사 하강법을 그대로 적용하면 된다.





