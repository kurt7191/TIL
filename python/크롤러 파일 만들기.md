# 크롤러 파일 만들기



0)크롤링 코드를 한 셀에 작성하고 .py 파일을 만들기



1)실행파일을 설치할 폴더로 이동(이 폴더는 py 파일이 만들어진 곳)

=> 크롤링 코드가 만들어진 곳에(py장소) 가서 pyinstaller 설치하기



2)!pip install pyinstaller

=> cmd 창에서 설치



3)pyinstaller --onefile daum_news_collector.py

=> 실행파일 만들기



4)dist 폴더 안에  daum_news_collector.exe 파일이 있음.



이를 실행시키면 크롤링이 수행이 되고 결과 파일을 저장함



<hr>



```python
%%writefile daum_news_collector.py
import os, re
import requests
from bs4 import BeautifulSoup as bs
import datetime

#주피터에서 py로 저장하기 위해서 셀 하나에 모두 넣어야함

#크롤링해서 저장할 파일 경로
os.chdir(r'C:\study\workspace_python\daum_news')


url = 'https://news.daum.net/'

soup = bs(requests.get(url).text,'lxml')

f = open(str(datetime.date.today())+'_article_total.txt', mode = 'w')

item_issue_list = soup.find_all('div', {"class":"item_issue"})

for i in item_issue_list:
    try:
        f.write(i.text + '\n')
        f.write(i.find_all('a')[0].get('href'))
        soup2 = bs(requests.get(i.find_all('a')[0].get('href')).text,'lxml')
        for j in soup2.find_all('p'):
            f.write(j.text)
    except:
        pass
f.close()
```



