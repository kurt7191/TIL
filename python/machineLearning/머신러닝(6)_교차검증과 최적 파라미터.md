# 교차검증과 최적 파라미터



### 교차검증해보기



```python
import numpy as np

np.mean(cross_val_score(knn, X_train, y_train))
```



### 최적의 하이퍼 파라미터 찾아보기



```python
temp = []

for i in range(1,20):
    knn = KNeighborsClassifier(n_neighbors = i)
    knn.fit(X_train, y_train)
    temp.append(knn.score(X_test, y_test))
```



반복문을 통해서 최적의 하이퍼 파라미터 값을 찾아볼 수 있음.



### GridSearchCV



GridSearchCV 를 통해서 모델의 최적의 하이퍼 파라미터값을 서칭할 수 있다.



```python
params = {
    'n_neighbors' : [2,3,4,5,6,7],
    'weights' : ['distance','uniform']
}
grid = GridSearchCV(knn, param_grid = params, cv = 5)
grid.fit(iris2.iloc[:,:-1],iris2.target)

```



grid 객체를 생성하고 param_grid 에 집어넣어볼 하이퍼 파라미터 값들을 넣어준다.



```python
#params의 요소개수의 곱만큼 나옴
df_score = pd.DataFrame(grid.cv_results_)
df_score[['params','mean_test_score','rank_test_score']]
```



모든 경우의 하이퍼 파라미터 경우의 수들의 테스트 점수들을 확인해본다.



```python
grid.best_params_
grid.best_score_
```



최적의 하이퍼 파라미터 값들과 점수를 확인할 수 있다.



### wine 데이터로 GridSearchCV 실습



```python
from sklearn.datasets import load_wine
data_wine = load_wine()
data_df = pd.DataFrame(data_wine.data, columns = data_wine.feature_names)
data_df['target'] = data_wine.target
```



사이킷런 와인 데이터 로드



```python
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV, train_test_split
```



모듈들 로드



```python
def all_models(X_train, y_train, cv = 10):
    #1. LogisticRegression
    lr = LogisticRegression()
    grid_lr = GridSearchCV(lr, cv =cv, param_grid = {'penalty':['l2']})
    grid_lr.fit(X_train, y_train)
    lr_pd = pd.DataFrame(grid_lr.cv_results_)
    
    #2. KNeighbors
    knn = KNeighborsClassifier()
    grid_knn = GridSearchCV(knn ,cv  = cv, param_grid = {'n_neighbors':[2,3,5]})
    grid_knn.fit(X_train, y_train)
    knn_pd = pd.DataFrame(grid_knn.cv_results_)
    
    return pd.concat([lr_pd, knn_pd], axis = 1)
    
```



각 모델 객체를 생성하고

하이퍼파라미터 설정할 값들을 `param_grid` 에 딕셔너리로 넣어준다. 



```python
all_models(wine.iloc[:,:-1], wine.target)
```



그에 따른 결과를 보여준다.



### pipe 사용하기



```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
```



파이프라인 모듈 불러오기



```python
pipe = Pipeline([('ss', StandardScaler()), ('knn',KNeighborsClassifier())])
```



객체 생성 `이름 + 객체 ` 로 생성가능.



```python
#pipe 자체에 설정할 수 있는 하이퍼 파라미터 값들
#pipeline은 알고리즘의 하이퍼 파라미터 이름을 앵글링한다.
#앵글링은 프로그램 자체에서 생성한 이름, 우리가 생성한게 아니라 이게 앵글리 기법

pipe.get_params()
```



 pipe 의 설정할 수 있는 하이퍼 파라미터 값들의 목록을 보여준다.

무조건 이 목록에 있는 걸로 grid를 설정해야 한다.



```python
#KNeighborsClassifier 하이퍼 파라미터 확인

pipe.steps[-1][1].get_params()
```



```python
#StandardScaler 하이퍼 파라미터 확인

pipe.steps[0][1].get_params()
```

이건 단순히 각 알고리즘마다의 하이퍼 파라미터 목록을 확인하는 것



```python
grid = GridSearchCV(pipe, {'knn__n_neighbors' : [2,3,4,5]})
X = wine.iloc[:,:-1]
y = wine.target

grid.fit(X,y)
```



학습시키고



```python
grid.best_params_
grid.best_score_
```



최적의 하이퍼 파라미터 값을 찾아주고, 점수를 찾아준다.



하지만 pipe 는 최적의 하이퍼 파라미터를 찾아주기는 하지만 최적의 알고리즘을 찾아주진 않는다.



### GridSearchCV 로 최적의 알고리즘 찾기



알고리즘을 바꾸면서 GridSearchCV 를 할 수 있다.



```python
pipe = Pipeline([('ss',StandardScaler()),('clf',KNeighborsClassifier())])
```



생성



```python
#pipe 에서 지정하는 하이퍼 파라미터 값 찾기.
pipe.get_params()
```



'clf': KNeighborsClassifier() 를 목록에서 확인할 수 있다.



```python
params = {
    'clf' : [KNeighborsClassifier(), LogisticRegression(max_iter=4000)]
}
grid = GridSearchCV(pipe, param_grid = params )
```



이걸 이용해서 grid 에다가 pipe 를 집어넣고 하이퍼 파라미터 목록에 다른 알고리즘을 집어넣으면 최적의 알고리즘을 찾는다.

(알고리즘 선택)



```python
params = [{
    'clf':[KNeighborsClassifier()], 'clf__n_neighbors' : [2,3,4,5]
},
{'clf':[LogisticRegression()], 'clf__penalty' : ['l2']}]

grid = GridSearchCV(pipe, param_grid = params)
```



알고리즘마다의 최적의 하이퍼 파라미터 찾기

딕셔너리를 나누어서 넣어줘야한다.



> 정리
>
> 하나의 알고리즘에 최적의 하이퍼 파라미터 찾는다.
>
> 최적의 알고리즘 선택 : 하나의 딕셔너리에 전부 넣어줘 찾는다. (pipe)
>
> 알고리즘마다의 최적의 하이퍼 파라미터는 알고리즘마다 딕셔너리를 만들어준다. (pipe)





