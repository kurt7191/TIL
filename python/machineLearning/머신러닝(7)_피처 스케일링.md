# 피처 스케일링



### StandardScaler



피처의 값들의 크기가 크면 머신러닝 성능에 안좋은 영향을 끼친다.

표준화를 시키는 작업.

가우시안 분포 즉, 정규분포를 만들어감



```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.datasets import load_breast_cancer
import pandas as pd

data_cancer = load_breast_cancer()
```



사이킷런 데이터 로드하기



```python
data_pd = pd.DataFrame(data = data_cancer.data, columns = data_cancer.feature_names)
data_pd['target'] = pd.DataFrame(data = data_cancer.target, columns = ['target'])

breast_cancer = data_pd.copy()
breast_cancer.head()
```



데이터 프레임 만들기



```python
ss = StandardScaler()
```



StandardScaler 객체 생성



```python
breast_cancer.describe().T['std'].nlargest()
```



표준편차 확인해보기



```python
X = breast_cancer.iloc[:,:-1]
y = breast_cancer.target
X_train, X_test, y_train, y_test = train_test_split(X,y, stratify = breast_cancer.target)
```



데이터를 나눈다.



```python
ss.fit(X_train[['worst area']])
ss.transform(X_train[['worst area']])
```



worst area 칼럼을 학습시키고 정규화 시키기

``fit_transform()` 을 사용하면 정규화 코드가 간편해질거 같다.



```python
X_train['worst area'] = ss.transform(X_train[['worst area']])

plt.title('worst area')
X_train['worst area'].hist()
```



표준화된 칼럼의 분포를 그래프를 통해서 확인 가능하다.

그래프의 모양이 완전 바뀌지는 않는다. (그래서도 안된다.)

표준화를 하여 데이터 각각의 크기가 줄어들순 있어도 그래프 전체 shape 이 크게 달라지진 않는다.



```python
#test 에다가도 똑같이 작업
X_test['worst area'] = ss.fit_transform(X_test[['worst area']])
```



**train 데이터에 스케일링을 적용했다면 test 데이터에도 스케일링을 적용해야 한다.**



### MinMaxScaler



StandardScaler 와 로직은 비슷하다.



```python
mm = MinMaxScaler()


# stratify는 데이터의 비율이 동일하게 나누는 옵션이다.
X_train, X_test, y_train, y_test = train_test_split(breast_cancer.iloc[:,:-1], 
                                                    breast_cancer.target, 
                                                    stratify=breast_cancer.target)

```



모델 객체를 생성하고, 데이터를 분리한다.



```python
mm.fit(X_train[['worst area']])
X_train['worst area'] = mm.transform(X_train[['worst area']])
```



`worst area` 칼럼을 스케일링 해줬다.



```python
lr = LogisticRegression(max_iter = 4000)
lr.fit(X_train, y_train)
lr.predict(X_test)
lr.score(X_test, y_test)
```



모델이 완벽한 성능을 보여주지 못하고 있다. 그 이유는 테스트 데이터에도 스케일링을 적용하지 않았기 때문이다.



```python
X_test['worst area'] = mm.fit_transform(X_test[['worst area']])
lr.predict(X_test)
lr.score(X_test, y_test)
```



테스트 데이터에도 스케일링 해주니 

모델이 완벽한 성능을 보여주고 있다.

