# Attention-based LSTM for Aspect-level Sentiment Classification



## Abstract



논문의 저자들은 sentence 의 감성 극단이 오직 sentence의 content(내용) 에 의해서 결정되는 것 뿐만 아니라 관계하고 있는 aspect에 의해서도 결정된다고 주장한다.

예를 들어서 *The appetizers are ok, but the service is slow.* 가 있으면,

aspect "taste" 에 집중해서 sentence의 감성을 파악하면 긍정이 나오는 반면에 "service" aspect 에 집중을 해서 sentence 의 감성을 파악하면 부정이 나온다.

따라서 aspect 와 content 의 내용 사이의 연결을 연구해보는건 보람이 있다.

논문의 저자들은 aspect 기반 감성 분류를 위한 Attention-based Long Short-Term Memory Network 를 제안한다.



어텐션 메커니즘은 다른 aspects(aspect 별로)들이 input 으로 받아들여질때, 문장의 다른 부분들에 집중을 한다.

논문에서 제안한 모델의 성능을 SemEval2014 데이터 셋을 이용해서 진행한다. 그리고 논문에서 제안한 모델이 aspect 단위의 감성 분류 작업에서 높은 성능을 보임을 보여준다.



<hr>

## Introduction



논문에서는 sentence 의 감성 극성이 content와 aspect 둘 다에 꽤 높게 관련 있음을 발견했다. (위의 예시를 통해서도 확인할 수 있다.)

예를 들어서, "Staff are not the friendly, but the taste covers all" 문장은 "service" aspect 에 초점을 두어서 감성 분석을 하면 부정이 나오지만 만일 "food" aspect 에 중점을 두어서 감성 분석을 하면 긍정이 나올 것이다.

즉, 다른 aspect들이 고려가 되어 sentence에 대한 감성을 분류하면, 감성 극성은 반대의 결과가 도출될 수 있다.



neural 네트워크 작업은 nlp 에서 많은 발전을 이루었는데, sentiment analysis 를 다루기에는 아직 성숙하지 않은면이 있다.

몇몇의 작업들은 target 의존 감성 분류는 target 정보를 고려함으로써 이익을 얻을 수 있다.

> ex) Target Dependent LSTM(TD-LSTM)
>
> Target- Connection LSTM(TC-LSTM)



이런 모델들은 target 만을 고려하고 aspect level 의 분류에 매우 중요하다고 입증된 aspect에 대해서는 고려하지 않는다.



논문의 저자들은 **특정 aspect에 대응하여 sentence의 중요한 부분**에 참여하기 위해서 attention 메커니즘을 사용한다. (attention 메커니즘은 관련있는 중요한 word 에 가중치를 크게 준다.)

논문은 **aspect 가 주어진 sentence의 중요 부분에 초점**을 둘 수 있는 aspect-to-sentence attention 메커니즘을 설계한다.

논문은 asepct level 의 감성 분류에서 감성 극성과 aspect의 잠재적인 상관관계를 연구한다.

> 주어진 aspect 에 대한 중요한 정보를 파악하기 위해서, attntion based LSTM 을 설계 (restaurants, laptop data 사용)





##### 논문의 Contribution

- attention-based Long Short Term 을 제안하고, 이는 효율적인 성능을 보였다.
- attention 동안의 aspect 정보를 고려한 두 가지 방법을 제안한다.
  - attention weights 들을 계산하기 위해서 sentence hidden representation 에 aspect vector를 합친다.
  - input word vector 에 aspect vector 를 합친다.
- 실험 결과는 논문의 접근 방식이 이전의 방식에 비해서 더 높은 성능을 보였음을 보여준다. 추가적으로 attention 메커니즘이 aspect level sentiment analysis 에 잘 적용됨을 보여준다.



## Related Work(literature?)



### Sentiment Classification at Aspect-level



현재의 접근의 주요 작업들은 언급된 entities들 또는 aspects들을 고려하지 않고 전체 문장의 감성 극성을 발견하는 시도들이다.

이때 lexicon 과 svm 모델을 사용했다. => 근데 비용이 많이 든다.





### Sentiment Classification with Neural Networks



word의 분산 표현에 대해서 얻을 수 있는 간단하고 효율적인 방법이 제안됐기 때문에 뉴럴 네트워크는 감성 분석에서 실질적으로 진전이 있었다.

지금까지 rnn 기반 모델들이 sentiment analysis 에 많이 사용됐다.

하지만 자료가 많이 없는 언어들의 경우에는 syntax parsing errors 들이 발생한다.



LSTM(TD-LSTM, TC-LSTM) 경우에 target dependent sentiment classification(target label 이 있는 감성 분류) 에서 높은 성능을 자랑했다. 



TC-LSTM 같은 경우 target 구에 포함되어 있는 word vector 들을 평균 냄으로써 target vector 를 구했다.

하지만 단순히 평균을 내는 것으로는 target 구의 의미론적 표현을 충분히 나타낼 수 없다.

>  target vector에 대해서 평균을 내는 작업은 최적 이하의 성능을 보였다.



위의 방법들의 강한 효율성에도 불구하고, 세분화된 aspect level 에서의 다른 감성 극성을 구별하는 것은 여전히 어렵다. 그러므로, 논문 저자들은 aspect 정보들을 완전히 사용할 수 있는 강한 뉴럴 네트워크를 디자인하려고 한다.



> LSTM 이 감성 분류에서 많이 사용되고 높은 효율을 보여왔다.



### Attention-based LSTM with Aspect Embedding



#### Long Short -term Memory(LSTM)



RNN 은 전통적인 피드포워드 뉴럴 네트워크 중 하나다. 하지만 전통적인 RNN 의 경우 기울기 소실 문제와 기울기 폭발 문제가 발생하기 때문에 사용하기 까다롭다.

 이를 극복하기 위해서 LSTM 모델이 탄생했다.





















































