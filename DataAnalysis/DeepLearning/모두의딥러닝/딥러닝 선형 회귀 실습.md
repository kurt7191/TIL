# 딥러닝 선형 회귀 실습



```python
df = pd.read_csv('C:\\Users\\user\\Desktop\\080228\\deeplearning\\dataset\\housing.csv',
                        delim_whitespace = True,
                     header = None
                       )

dataset = df.values
X = dataset[:,0:13]
Y = dataset[:,13]
X_train,X_test,y_train,y_test = train_test_split(X,Y, test_size = 0.3, random_state = 1)

model = Sequential()
model.add(Dense(30, input_dim = 13, activation = 'relu'))
model.add(Dense(6, activation = 'relu'))
model.add(Dense(1))

model.compile(loss = 'mean_squared_error',
             optimizer = 'adam')

model.fit(X_train, y_train, epochs = 200, batch_size = 10)

Y_prediction = model.predict(X_test).flatten()

for i in range(10):
    label = y_test[i]
    prediction = Y_prediction[i]
    
    print('실제가격 : {:.3f}, 예측가격 : {:.3f}'.format(label, prediction))
```



분류와 다른점



model.compile 할 때, metrics 설정을 안한다.

이는 loss 에 이미 mse 가 있기 때문.

분류 모델의 평가 지표는 오차분류표, 정확도, 재현율, 정밀도, f1_score 등등이 있으며

선형회귀 같은 경우 mse 같은 평가 지표가 있다.



선형 회귀 모델 경우 `model.predict()` 안에 새로운 데이터(즉, 테스트 x데이터)를 주면 이에 맞는 예측 수치를 출력한다. 근데 이게 일차원적으로 기록되어 있는 게 아니라 그 이상 차원으로 기록되어 있을 수 있다. 이러면 읽기가 힘들기 때문에 1차원으로 펴줘야 한다. 이 때 사용하는 게 `flatten()` 함수이다.



또 model 을 구축할 때, 나는 은닉층의 activation 함수가 relu 나 시그모이드가 아닐 줄 알았는데, relu 였고, 선형회귀는 이진 분류나, 다중 분류와 다르기 때문에 출력층에 activation 함수를 적어주지 않고 값 그대로를 출력했다.

