# 빅데이터 분석 7주차



이번주차 딥러닝에 대해서



### 딥러닝



1. 딥러닝 개요
2. cnn
3. rnn



##### 딥러닝 개요



딥러닝은 인공지능 기술 중 하나

(인공지능, 인간의 지능을 기계가 흉내를 내는 것)



인공지능 기술

-머신러닝

학습데이터로부터 패턴을 찾아내고 모형을 만들어 내고, 모형을 통해서 결과를 만들어 낸다.



-인공신경망

은닉층을 2개 이상 사용하지 않는다.



-딥러닝

은닉층을 수천 개 쌓아 올린 것이 딥러닝 기술이라고 함.



##### 딥러닝의 주요 기법들



cnn, rnn, 강화학습 등등



##### cnn



시신경의 작용을 많이 따라했다. 따라서 주로 이미지 인식에 활용한다.



##### rnn



순차적인 입력처리에 적합한 딥러닝

자연어 처리에 좋은 성능, 시계열 데이터에도 많이 사용된다.

언어 모델링, 텍스트 생성, 자동 번역, 음성 인식, 이미지 캡션 생성에 사용됨



전통적인 rnn 의 경우 오래된 기억을 사용하지 못함.

따라사 lstm, gru 를 더 많이 사용함(rnn 구조)



##### 강화학습



알파고에도 쓰였던 모델



에이전트가 액션을 한다. 환경은 이 액션에 대해서 점수를 준다. 

에이전트는 이 점수를 향상하기 위해서 자신의 액션을 보완한다.



##### GAN



생성자(제너레이터)와 식별자(디텍터)라는 신경망(네트웍)을 이용한다.

생성자에게 실제 이미지를 주고, 생성자에게 이거와 비슷한 가짜를 만들어 보라고 한다.

생성자가 가짜를 비슷하게 만들고 진짜와 가짜를 디텍터에게 주면서 어느 게 진짜인지 찾아보라고 한다.

이 과정을 계속 반복하다 보면, 생성자는 가짜를 잘 만드는 기술을 습득하게 되고 디텍터는 가짜와 진짜를 잘 구분할 수 있게 된다.



##### 전이 학습



훈련 데이터가 적은 경우에 사용하는 기법

데이터가 적으면 유사영역에서 학습했던 쓰였던 데이터를 쓴다



문서를 통해서 패턴을 찾고 모델을 학습(기사라든가, 위키피디아 같은 것들)

이 모델을 통해서 감정 분석 등등을 한다.



BERT 라는 기술이 전이 학습에서 대표적

GTP-3 라는 언어 모델 존재

(굉장히 큰 언어 모델, BERT 도 큰 모델이지만 BERT 의 300배 정도되는 대용량 언어 모델)



ZERO-SHOT, ONE-SHOT, FEW-SHOW러닝 같은 것들이 가능하다고 생각함



ZERO-SHOT 러닝 같은 경우 머신러닝 할 때 EXAMPLE 을 하나도 안주고 TASK 만 주는 것

예를 들어서 사과를 영어로 번역하면 뭐야? 라고 물어보는 것.



ONE-SHOT 러닝은 예시를 하나만 주고 테스크를 주는 것



FEW-SHOT 은 몇 가지 예시를 주고 테스크를 주는 것



대용량 언어 모델이 있는 경우에는 학습을 하지 않고도 꽤 괜찮은 성능을 얻을 수 있다거 최근에 발표가 되고 있다.





SQuAD

(QNA 시스템의 대표적인 데이터 셋)



스탠퍼드 대학에서 만든 데이터 셋



쿼리 데이터 셋 2개가 있다.



1 경우에는 머신러닝 TASK 가 한 개 주어진다. (토플같은 지문 1개)



지문 제시, 지문과 관련된 문제가 존재, 그것과 관련된 답을 주관식으로 답을 해야한다.



<HR>

##### CNN



- 기존 신경망

FULL-CONNECTED (완전 연결)

앞의 층의 노드들과 다 연결되는 구조



- CNN

CNN은 앞의 노드들과 다 연결되지 않는다.

CNN은 두 가지 LAYER 가 더 있다.

합성곱 계층과 풀링 계층이다.



1. 합성곱 계층(CONVOLUTIONAL LAYER)



어떤 이미지를 인공신경망에서 처리하기 위해서는 입력 계층이 하나이기 때문에 이미지의 픽셀값들을 1차원으로 바꿔야 한다. 이렇게 되면 공간에 대한 정보가 손실된다.



하지만 합성곱 계층은 그 이미지 형상을 그대로 유지시킨다. 따라서 공간적인 정보나 로칼 정보를 잘 유지시킨다.



> 합성곱 연산은 어떻게 이루어지는가?
>
> EX, 입력 데이터가 4X4 로 되어 있다고 해보자. 그리고 필터가 있다. (필터는 학습을 통해서 만들어진다.)
>
> 연산 FMA (단일 곱셉 누산, FUSED MULTIPLE ADD) - 대응되는 것끼리 곱해서 더하는 방식
>
> 
>
> 4X4 입력, 3X3 필터, 3X3 위치를 옮겨가 주면서 곱하고 마지막에 편향(BIAS) 를 더한다.
>
> 이때 STRIDE 가 필터를 얼마나 움직이냐를 말해주는 수치인데, 1로 정하면 1칸씩 이동하고, 2로 정하면 2칸씩 이동해서 연산을 진행한다.



- 패딩(PADDING)

(입력데이터 주변의 특정값으로 채워주는 것)



앞에 합성곱을 하면 데이터가 줄어들었다.

데이터가 줄어들지 않기 위해서 패딩을 넣는다.

입력데이터 4X4 에 패딩을 1넣어주면 6X6 입력데이터로 변한다. 그 상태에서 필터를 곱하면 4X4의 출력 데이터로 출력된다.

이렇게 되면 데이터의 손실이 없어진다.



- 3차원 데이터의 합성곱 연산

  보통 이미지는 2차원 이미지라고 하지만 사실은 채널이 3개 있다. 보통은 RGB 이다.

  따라서 필터도 3장이 들어간다. R,G, B 따로 따로,

  각 채널별로 필터가 적용 된 이후에 해당되는 것 별로 더한다.



2. 풀링 계층



가로 세로 방향의 차원을 줄이는 역할



4X4 입력 데이터가 있고 2X2 MAX 풀링을 한다면, STRIDE가 2일 때, 입력데이터 안에서 2X2 별로 2씩 이동을 하면서 2X2 안에 있는 데이터 중 가장 큰 데이터를 선택하여 2X2 출력 결과를 만든다.



채널이 3개라면 3개의 결과가 나온다.



풀링을 적용하는 이유는 입력 중에 중요한 부분만 추출하기 위해서이다.

입력의 미세한 변화에 변화를 덜 주게 된다.



CNN은 합성곱과  풀링을 연결해서 만들어진다.



CONV가 오고 전환함수(RELU) 쓰고 풀링 - 이게 몇번 반복

그리고 AFFINE 계층으로 해서 쭉 펴준다. (1차원으로)

그 다음에 TRANSFER FUNCTION ,AFFINE LAYER, SOFTMAX 함수로 이루어진다.



이런 식의 구조로 CNN이 구성이 된다.



필터가 학습을 통해서 만들어진다.



앞쪽의 필터는 EDGE, 윤곽들을 찾는 필터들 만들어지고

TEXTURE , OBJECET 파트들을 식별하는 필터들이 그 이후에 만들어진다.



<HR>



##### RNN

시퀀스 데이터 모델링에 많이 쓰이는 구조

시퀀셜한 입력 데이터가 들어간다.

그래서



X0~ XT까지시퀀셜한 INPUT 데이터가 들어간다.

Ht(hidden state), Xt 가 들어가면 Ht가 만들어진다. 근데 ht 가 다시 입력이 되는 구조



프로세스를 잠깐 정리해보면



X0 이 들어가서 H0 이 만들어지고 그 다음 X1과 H0 이 같이 들어가서 H1 이 만들어지고 X2와 H1이 들어가서 H2 가 만들어진다. 이 구조가 쭈욱 반복

(은행 잔고 프로세스와 똑같다고 생각하면 된다.)



이러한 rnn 은 심플 rnn

그냥 rnn은 output 상태가 하나 더 추가된다.

앞에 보다 w가 하나 더 추가 되고 bias 가 하나 더 추가된다.



이러한 rnn 은 **기울기 소실 문제**를 가지고 있다.

너무 오래된 것들에 대해서는 기억을 잘 하지 못한다.



따라서 gate 를 추가한 rnn 이 고안이 됐다.

이런 것들 중에 대표적인게 Long Short Term Memory(LSTM), Gated Recurrent Unit(GRU)



LSTM 에 비해서 GRU 가 훨씬 더 간단한 구조



- seq2seq

RNN 두 개를 결합한 구조를 Sequenct to Sequence 구조라고 부른다.(seq2seq)



앞에 있는 rnn = Encoder, 뒤에 있는 rnn 을 Decoder



번역기에 이런 구조가 많이 사용된다. 예를 들어서 Hello World 가 들어가면 그게 Encoder 가 도니ㅡㄴ 것이고 최종 결과가 hidden state라고 부르는데, 그게 최종 결과가 된다.



그게 decoder 부분에서는 번역이 되는 것,



"입력 rnn + 히든 + 출력 rnn"



<hr>

### 딥러닝 실습



1. 전통적인 인공신경망을 이용한 손글씨 인식
2. CNN을 이용한 손글씨 인식
3. RNN을 이용한 감성분석(긍부정 분류)





























































