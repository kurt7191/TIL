# 빅데이터분석(14) - 자연어처리(1)

> Bag OF Words 와 Document - Term 행렬
>
> DTM (DOCUMENT TERM) - 영어
>
> DTM (DOCUMENT TERM) - 한글



하나의 문서를 단어들의 BAG으로 본다.

이때 BAG은 가방이 아니라

집합론에서의 BAG

즉, 하나의 문서를 단어들의 집합으로 본다.



SET 같은 경우는 어떤 단어가 그 BAG 에 속한는지 안하는지에 관련된 것.

BAG 같은 경우는 어떤 단어가 속하는지 안속하는지, 그리고 속한다면 몇 번 속하는지에 관한 것.



예를 들어서 ABC, AABC 있으면 집합은 A가 속해있는지 안속해있는지만 보지만, BAG 은 A가 속하는데 몇 번 속하는지를 카운팅 한다. (이게 바로 BAG OF WORDS APPROACH)



<HR>

## DOCUMENT - TERM MATRIX



DTM : 

문서를 다룰 때, 문서 안에 있는 단어들이 얼마나 출현하는지 `BAG OF WORDS APPROACH` 특징으로 해서표현하는 방법



DTM 도 두 가지 방법이 존재

1. 빈도 기반
   - This movie is too slow : 가 있으면 칼럼을 각 단어들로 만들고 각 단어가 나온 횟수를 행의 값으로 가짐
2. TF-IDF 기반(Term Frequency-Inverse Document Frequecy)
   - 문서에 많이 나온 단어 + 전체 문서에서 얼마나 희귀하게 나왔는지 같이 고려하는 방법
   - TF * IDF 를 곱해서 계산이 됨.
   - TF(빈도수) 뿐만 아니라 단어의 중요도(IDF) 를 함께 고려함, 빈도수 뿐만 아니라 단어의 중요도도 구하는 것
   - TF = 이 문서에 해당 단어가 출현한 횟수/ 이 문서의 전체 단어의 수
     - `This movie is not scary and is slow` 에서 movie's tf =  1/8
   - IDF = LOG{ 전체 문서의 수 / T TERM 을 포함한 문서}
     - `This movie is very scary and long`
     - `This movie is not scary and is slow`
     - `This movie is spooky and good`
     - this -> log { 전체 문서의 수 3개 / this 포함한 문서 3개 } = log (1) = 0
     - scary -> log { 3 / 2} = 0.18
     - not, slow -> log { 3/1} = 0.48
     - 문서에 드물게 나올수록 idf 가 높은 값을 가짐, 즉 문서에 드물게 나올수록 중요한 단어로 간주함
   - TF - IDF 같은 경우는 앞서 구한 TF * IDF 라고 할 수 있다.



<HR>

## 실제로 PYTHON 에서 DTM 을 어떻게 구현하는지



### 영어

### CountVectorizer 사용



```python
from sklearn.feature_extraction.text import CountVectorizer

vector = CountVectorizer()
print(vector.fit_transform(review_df['comment']).toarray())
print(vector.vocabulary_)
```



### TfidfVectorizer 사용



```python
from sklearn.feature_extraction.text import TfidfVectorizer

tfidfv = TfidfVectorizer()
print(tfidfv.fit_transform(review_df['comment']).toarray())
print(tfidfv.vocabulary_)
```



### 한글

### CountVectorizer 사용



```python
from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer()
print(vectorizer.fit_transform(review_df['comment']).toarray())
print(vectorizer.vocabulary_)
```



### TfidfVectorizer 사용



```python
from sklearn.feature_extraction.text import TfidfVectorizer

tfidfv = TfidfVectorizer()
print(tfidfv.fit_transform(review_df['comment']).toarray())
print(tfidfv.vocabulary_)
```



<hr>













