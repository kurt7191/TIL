# 빅데이터분석(10) - 데이터 크롤링



- 첫 번째 웹 스크레이퍼
- 웹 페이지 가져오기
- HTML

<HR>



### HTML 이해하기



- 웹페이지가 어떻게 구조화 되어 있는지 브라우저로 하여금 알 수 있도록 하는 `마크업 언어` 

- `ELEMENT ` 들로 구성이 되어 있다.
- 중첩이 되어서 ELEMENT 들이 사용될 수 있다.



##### ELEMENT



1. 블록 레벨 요소
   - 블록 레벨 요소 :  태그가 들아가면 앞뒤에 줄바꿈이 들어간다.
   - 웹 페이지 상에 블록을 만드는 요소
   - 블록 레벨 요소는 앞뒤 요소 사이에 새로운 줄을 만듦
2. 인라인 요소
   - 항상 블록 레벨 요소 내에 포함
   - 문장, 단어 같은 작은 부분에만 적용
   - 새로운 줄(LINE) 을 만들지 않음
3. 빈 요소
   - 모든 요소가 여는 태그, 내용, 닫는 태크 패턴을 따르지 않음
   - 대표적으로 IMG 태그
   - CLOSING 태그가 존재하지 않음
   - SRC 의 ATTRIBUTE 를 가지고 있음



##### ATTRIBUTE(속성)



ELEMENT 는 속성을 가질 수 있음.

웹브라우저 상에는 보이지 않는다.



속성 예제



```htm
#href 가 a 태그의 attribute 의 속성이다.
#title은 링크에 대한 추가 정보를 나타낸다.
#target 은 링크가 어떻게 열릴 지 지정, blank 새 탭에서 보여줌

<a href = ' ', title = ' ', target = ' '></a>

```



<hr>



### BeautifulSoup 설치와 실행



- BeautifulSoup 설치와 실행

- 신뢰할 수 있는 연결 만들기 (어떻게 안전하게 크롤링 커넥션을 만들 수 있을지)



<hr>

> 꿀내용 :  BeautifulSoup 의 거북이가 읽은 시 제목이 BeautifulSoup 이라서 만듬



<hr>



##### BeautifulSoup 실행 예제



```python
from urllib.request import urlopen
from bs4 import BeautifulSoup

html = urlopen('http://www.pythonscraping.com/pages/page1.html')

#html.parser 는 이 문서를 html.parser 로 해석해서 beautifulsoup 객체로 만드는 것

bs = BeautifulSoup(html.read(),'html.parser')
print(bs.h1)

#hirachy 대로 요소 접근을 할 수 있다.

print(bs.html.body.h1)
print(bs.body.h1)
print(bs.html.h1)
```



<hr>



##### 신뢰할 수 있는 연결



웹페이지 자체는 완전하지 않고 불완전한하다.

따라서 가능한 오류들이 여러가지가 있는데 가능 한 오류들은 아래와 같다.

크롤링을 하던 중 오류가 나면 크롤링 프로그램이 중단이 된다.



##### 

- 크롤링할 때 가능한 오류

1. 서버를 찾을 수 없는 경우
2. 페이지를 찾을 수 없거나, URL 해석에서 에러가 생긴 경우
3. 해당 태그가 존재하지 않는 경우



- 해결책 : 

`try, except` 를 활용해서 가져오면 해결할 수 있다.



try, except를 사용해서 크롤링한 예제



```python
from urllib.request import urlopen
from urllib.error import HTTPError #원하는 페이지가 없는 경우 리턴
from urllib.error import URLError #서버가 존재하지 않는 경우

try:
    html = urlopen("https://pythonscrapingthisurldoesnotexist.com")
except HTTPError as e:
    print('The server returned ann HTTP error')
except URLError as e:
    print('The servr could not be found')
else:
    print(html.read())
    
```



함수로 작업 처리 일반화 하기



```python
def getTitle(url):
    try:
        html = urlopen(url)
        
    except HTTPError as e:
        return None
    except URLError as e:
        return None
    
    try :
        bsObj = BeautifulSoup(html.read(), 'html.parser')
        title = bsObj.body.h1
    except AttributeError as e: #태그가 존재하지 않을 때는 AttribueError 
        return None
    
    return title


title = getTitle("http:///www.pythonscraping.com/pages/page1.html")

if title == None:
    print('Title could not be found')
else:
    print(title)
    
        
        
        
```



<hr>

### BeautifulSoup을 이용한 HTML 다루기



- find() 와 findAll()
- 트리 이동
- 정규 표현식
- select()



<hr>

##### CSS, span, div



find 와 findAll 을 하기 전에 알아야 한다.



1. css :  꾸며주는 것



2. span과 div는 웹페이지의 구간을 정의할 때 사용한다.

- span : 자동 줄 바꿈이 됨

- div : 줄 바꿈이 되지 않음



<hr>



1. findAll()

   - 원하는 모든 것을 다 찾아준다.

   - 원하는 태그에 원하는 속성을 갖는 것을 찾을 수 있다.

   - 즉, 원하는 태그에 접근하고, 그 태그가 특정 속성을 가지는 값만 추출하여 꺼낼 수 있다.

   - ```python
     #특정 태그의 특정 속성을 가진 값들을 가져오는 법
     name_dialog_List = bs.findAll('span',{'class':'green'})
     
     #특정 태그의 특정 속성을 가진 값들을 가져오는데, 특정 속성이 여러 개일 경우
     name_dialog_List = bs.findAll('span', {'class':{'green','red'}})
     ```

   - recursive 인자가 존재한다. recursive 를 True 를 하면, 자식 태그와 자식의 자식을 검색

   - False 로 하면 문서의 최상위 태그만 찾음

   - 여러 태그를 동시에 찾을 수도 있다.

     - ```python
       headerList = bs.findAll({'h1','h2','h3','h4','h5','h6'})
       for header in headerList:
           print(header.get_text())
       ```

   - text 인자는 태그 미포함 텍스트만 찾는다.

     - ```py
       #the prince가 되어있는 텍스트가 몇 번 나오는지 확인 가능하다.
       princeList = bs.findAll(text = 'the prince')
       print(len(princeList))

2. find

   - 원하는 것 첫 번째만 찾아준다.



##### 형제 다루기



```python
#첫 번째 tr 제외하고 그 이후 tr부터 출력

for sibling in bs.find('table',{'id':'giftList'}).tr.next_siblings:
    print(sibling)
```



테이블 형태의 html 파일을 가져올 때, 첫 번재 tr 태그를 제외하고 그 이후의 tr을 가져오고 싶다고 하자.

html 파일의 table 이 표 형식으로 되어 있는데, 아마 첫 번째 tr 은 header 가 될 것이다.

이 header 을 제외한 tr 정보를 가져오고 싶다면, `tr.next_siblings` 를 해주면 된다.



>  `next_sibling` 하면 바로 다음 거 `하나` 만
>
> `previous_siblings` 하면 그 이전 것들 전부
>
> `previous_sibling` 하면 그 이전 것 `하나` 만



> `parent` 하면 바로 부모만
>
> `parents` 하면 부모의 부모까지



부모 이용 예시

```python
bs.find('img',
       {'src':'../img/gifts/img1.jpg'}).parent.previous_sibling.get_text()
```



<hr>

### 정리



beautifulSoup 으로 html 파일 받아서 객체 생성



bs객체를 이용해서 요소 접근 가능

요소 접근 방법은 find , findAll



요소를 접근할 때, 태그의 특정 속성값도 찾을 수 있음. (복수 속성을 찾는 것도 가능)



부모와 형제의 관계를 이용해서 태그에 접근할수도 있음

그 방법은 next_sibling,next_siblings, previous_sibling,previous_siblings, parent, parents 등등



속성이 class 인 값들 중 특정 class 값을 가지는 태그 모두를 가져오고 싶다면

`findAll(True, {'class' : '원하는값' }`  하면 된다



그리고 class 제외하고 어떤 특정 속성의 값을 `하나` 찾고 싶다면

`find(id = '원하는 거')` 하면 된다.



<hr>

### 정규 표현식



규칙을 만족하는 문자열을 찾을 때 사용하는 것



`aa*bbbbb(cc)*(d|)`



위는 정규 표현식



a가 최소한 한번 이상 => `a*`

b는 무조건 5번 => `bbbbb`

c는 짝수번만 => `(cc)*`

d는 있어도 되고 없어도 되고 => `(d|)`



<hr>

### select(), select_one()



select() == findAll()

select_one() = find()



select 경우, return 값이 리스트 형태이다.



```python
from urllib.request import urlopen
from bs4 import BeautifulSoup
html = urlopen('http://www.pythonscraping.com/pages/page3.html')
bs = BeautifulSoup(html,'html.parser')

title = bs.find('h1')
print(title.get_text())

title1 = bs.select_one('h1')
print(title1.get_text())

title2 = bs.select('h1') #return 값이 리스트 형태이다.
print(title2[0].get_text())
```





select 에서는 하위 태그를 어떻게 검색하는가?



```python
table = bs.find('table').findAll('tr')
for tr in table:
    print('='*10)
    print(tr.get_text())
   
```

find 에서는 하위 태그에 접글 할 때, 상위 태그를 먼저 find 를 통해서 찾고 그 찾은 것에서 한 번더 find나 findall 을 사용해서 찾는다.



```python
table1 = bs.select('table tr')
for tr in table1:
    print('='*10)
    print(tr.get_text())
```



select 를 사용하면 하위 태그에 대해서 ` `, 공백을 통해서 심플하게 접근할 수 있다.





##### select의 직계 자손만 검색



`>` 를 이용해서 직계 자손을 표현한다.



```python
table1 = bs.select('table > tr')

for td in table1:
    print('='* 10)
    print(td.get_text())
```



table 의 직계 자손인 tr만 찾으라는 것, 손자는 안됨

위의 `table tr` 과 똑같은 결과를 가져온다.



```python
table1 = bs.select('table > td')

for td in table1:
    print('='* 10)
    print(td.get_text())
```



table 의 직계 자손인 td만 찾으라는 것, 손자는 안됨

그런데 html 의 table을 살펴보면  table > tr > td 순으로 적혀있다.

따라서 td는 손자격이기 때문에 출력이 되지 않는다.



##### select 의 특정 class 값에 접근



findall 같은 경우에는 딕셔너리 형태로 값을 넣어줘서 찾음.

그러나 select 같은 경우에는 `.` 을 통해서 class 값을 표현.



```python
#태그의 class 탐색

table = bs.find('table').findAll('tr',{'class':'gift'})
for tr in table:
    print('=' * 10)
    print(tr.get_text())
    
    
table1 = bs.select('table tr.gift')
for tr in table1:
    print('=' * 10)
    print(tr)
    
   
```



##### select 의 특정 요소 값에 접근



select의 요소 접근은 `#` 으로 한다.

```python
table = bs.find('table',{'id':'giftList'})
for tr in table:
    print(tr)
    
table1 = bs.select('table#giftList')
for tr in table1:
    print(tr)
```



##### select의 요소와 class 둘다 접근하는 방법



find, findall 은 딕셔너리 안에 class와 요소 값을 넣어준다.

반면에 select는 `.` 으로 class 값 접근하고 `#` 으로 요소값에 접근한다.





```python
table = bs.find('table').findAll('tr',{'class':'gift','id':'gift2'})
for tr in table:
    print(tr)
    
    
    
table2 = bs.select('table tr.gift#gift2')
for tr in table2:
    print(tr.get_text())
```

