# 빅데이터분석(13) - 자연어처리(3)



## 자연어 처리 전처리 단계



### 영어

##### 

##### 1.소문자로 바꾸고 숫자, 문장부호, 특수문자 제거하기



```python
import pandas as pd

review_df = pd.read_csv('C:\\study\\workspace_python\\pdsample\\datasets\\mydata\\imdb_minari.csv')

#소문자로 모두 바꾸기
review_df['comment_n'] = review_df['comment'].apply(lambda x : x.lower())

#숫자, 문장부호, 특수문자 제거

import re

p = re.compile("[0-9]+") #0에서 9까지의 글자가 하나 이상 반복된다는 뜻
review_df['comment_n'] = review_df['comment_n'].apply(lambda x : p.sub(" ",x))
#p 에 해당하는 걸 만나면 " "로 바꿔라

#w => 숫자나 문자나 언더바
#W => 숫자나 문자나 언더바가 아닌 것들
p = re.compile("\W+")
review_df['comment_n'] = review_df['comment'].apply(lambda x : p.sub(" ",x))

```



##### 2. 불용어(stopwords) 제거



```python
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

stop_words = set(stopwords.words('english'))

review_df['comment_n'] = review_df['comment_n'].apply(lambda x : word_tokenize(x))

def remove_stopwords(word_tokens):
    result = []
    for w in word_tokens:
        if w not in stop_words:
            result.append(w)
    return result

review_df['comment_n'] = review_df['comment_n'].apply(lambda x : remove_stopwords(x))
```



##### 3. 어간 추출하기



```python
from nltk.stem import WordNetLemmatizer

n = WordNetLemmatizer()

review_df['comment_n'] = review_df['comment_n'].apply(lambda x :[n.lemmatize(w) for w in x])

review_df.to_csv('imdb_minari_result.csv', index = False)
```



<hr>

### 한국어 



##### 1. 띄어쓰기



```python
review_df = pd.read_csv('C:\\study\\workspace_python\\pdsample\\datasets\\mydata\\daum_minari.csv')

#띄어쓰기 패키지
from pykospacing import Spacing

review1="""
죄송한데 이영화 도데체 어느 포인트에서 감동을 하라는 거죠?
진짜 모르겠어서 그래요 알려주세요 제발...
그래미는 외국어 영화상은 왜 준거지?
정말 미나리로 감동 받고 싶으면
이 미나리말고 다른 미나리 추천드릴께요
미나리로 대박 눈물뽑은 헬로 고스트가 훨 낫음...
헬로고스트 미나리가 백번 감동 줌...
미나리신드롬은 마치 동화 벌거벗은 임금님 같다
기생충이 아카데미 올라왔으니 금년에도 한국꺼 뭐 없나?
어 미나리? 어라 미국 자본이야? 오 한류랑 미국 자본의 콜라보영화 
이거 이슈 되겠는데?
그래서 매스컴에서 연신 띄워서 환상을 현실로 만들어준 영화
재미없는데 일단 이슈는 되었으니 상은 줘야겠고...
그렇게 상탔다니까 아 재미있는거야라고 
스스로 셀프최면 거는거지...
마치 벌거벗은 임금님처럼
아나123진짜
"""


review2="""
초보 감독의 미숙한 연출로 흐름이 이어지지 못하는 
아쉬움이 많은  영화네요.   
시대를 잘 타고 나와서 아카데미 후보에 오르는 
운빨이  90%랄까 ~~   
마더같은 영화가  지금 나왔다면 아카데미상을 휩쓸건데,,,  
아무튼 후보에 거론되는것도  살짝 민망한 정도 ~~
"""

spacing = Spacing()
kospacing_sent = spacing(review1)
print(kospacing_sent)
print(review1)

review2_spacing = spacing(review2)
print(review2_spacing)
print(review2)



```



##### 2. 문장으로 분리



```python
#문장 분리
#문장별로 token 내주는 kss 패키지
import kss

review1_split = kss.split_sentences(kospacing_sent)

review2_split = kss.split_sentences(review2_spacing)
review2_split
```



##### 3. 숫자 제거, 특수문자 제거



```python
#숫자 제거

import re

p = re.compile("[0-9]+")
review1_n_remove = []
for sentence in review1_split:
    review1_n_remove.append(p.sub(" ",sentence))
print(review1_n_remove)

review2_n_remove = []
for sentence in review2_split:
    review2_n_remove.append(p.sub(" ", sentence))
print(review2_n_remove)

#특수문자 제거
p = re.compile("\W+")
review1_p_remove = []
for sentence in review1_n_remove:
    review1_p_remove.append(p.sub(" ",sentence))
print(review1_p_remove)


review2_p_remove = []
for sentence in review2_n_remove:
    review2_p_remove.append(p.sub(" ",sentence))
print(review2_p_remove)
```



##### 4. 맞춤법 검사



```python
from hanspell import spell_checker

spell_checker.check(review1_p_remove[0])

review1_spell = []
for sentence in review1_p_remove:
    review1_spell.append(spell_checker.check(sentence).checked)
    
review2_spell = []
for sentence in review2_p_remove:
    review2_spell.append(spell_checker.check(sentence).checked)
```



##### 5. 문장을 형태소 단위로 토큰화



```python
#형태소 분석기를 이용한 토큰화

from konlpy.tag import Okt
okt = Okt()

review1_token = []
for sentence in review1_spell:
    review1_token.append(okt.pos(sentence))

review2_token = []
for sentence in review2_spell:
    review2_token.append(okt.pos(sentence))   
    
#명사, 동사, 형용사만 추출

review1_tokens1 = []
for sentence in review1_token:
    new_sent = []
    for token in sentence:
        if (token[1] == "Noun" or token[1] == "Adjective" or token[1] == 'Verb'):
            new_sent.append(token)
    review1_tokens1.append(new_sent)
    
review2_tokens1 = []
for sentence in review2_token:
    new_sent = []
    for token in sentence:
        if (token[1] == "Noun" or token[1] == "Adjective" or token[1] == 'Verb'):
            new_sent.append(token)
    review2_tokens1.append(new_sent)
```



##### 6. 표제어 추출

형용사 동사의 어간



```python
#표제어 추출

from soylemma import Lemmatizer

lemmatizer = Lemmatizer()
lemmatizer.analyze("차가우니까")
lemmatizer.lemmatize("차가우니까")
lemmatizer.analyze('한국어')
lemmatizer.lemmatize("몰라서") #결과가 여러 개 나올 수 있음.
lemmatizer.lemmatize("그래요")

review1_stem = []
for sentence in review1_tokens1:
    new_sent = []
    for token in sentence:
        if (token[1] == 'Adjective')|(token[1]=='Verb'):
            stem_result = lemmatizer.lemmatize(token[0])
            if len(stem_result) != 0:
                new_sent.append(stem_result[0])
        else:
            new_sent.append(token)
    review1_stem.append(new_sent)
    
review2_stem = []
for sentence in review2_tokens1:
    new_sent = []
    for token in sentence:
        if (token[1] == 'Adjective')|(token[1]=='Verb'):
            stem_result = lemmatizer.lemmatize(token[0])
            if len(stem_result) != 0:
                new_sent.append(stem_result[0])
        else:
            new_sent.append(token)
    review2_stem.append(new_sent)
```



##### 7. stopwords 제거 및 형태소 태그 제거



```python
#Stopwords 제거

stopwords=[('이','Noun'), ('거','Noun'),('오','Noun'), ('것','Noun')]
review1_stop=[]

for sentence in review1_stem:
    new_sent = []
    for token in sentence:
        if token not in stopwords:
            new_sent.append(token)
    review1_stop.append(new_sent)
            
review2_stop = []
for sentence in review2_stem:
    new_sent = []
    for token in sentence:
        if token not in stopwords:
            new_sent.append(token)
    review2_stop.append(new_sent)
    
    
#pos 태그 제거

review1_final = []
for sentence in review1_stop:
    new_sent = []
    for token in sentence:
        new_sent.append(token[0])
    review1_final.append(new_sent)
    
review2_final = []
for sentence in review1_stop:
    new_sent = []
    for token in sentence:
        new_sent.append(token[0])
    review2_final.append(new_sent)

```



##### 8. one list 로 만들기



```python
#one list로 만들기

review1_final1 = []
for sentence in review1_final:
    review1_final1.extend(sentence)
print(review1_final1)



review2_final2 = []
for sentence in review2_final:
    review2_final2.extend(sentence)
print(review2_final2)

```

