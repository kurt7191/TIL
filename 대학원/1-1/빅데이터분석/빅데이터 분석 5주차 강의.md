# 빅데이터 분석 (5)



### 방향성 데이터분석 절차와 평가척도



##### 예측모형과 프로토타입



입력변수와 목표변수가 같은 프레임에 있느냐에 따라서 예측모형과 프로토타입으로 나뉜다.



1. 예측모형
   - 입력변수가 목펴변수보다 시간상 앞선 것
2. 프로토타입
   - 입력변수와 목표변수가 시간상 동일한 것



##### 데이터 분석 절차



1. 경영 문제를 데이터마이닝 문제로 번역한다.

   - 제대로된 비즈니스 문제에 대한 인식에서 시작한다.
   - 비즈니스 문제를 데이터 분석을 통해서 해결할 수 있는 문제로 재정의한다.

2. 적절한 데이터를 선택한다

   - 기업이 가지고 있는 데이터를 살펴보고 쓸만한 데이터 선택
   - 어느 정도의 데이터 양이 필요한지 등등

   

3. 데이터에 대한 지식을 얻는다.

   - 우리가 가지고 있는 데이터들이 어떤 특성을 가지고 있는지 파악
   - EDA

4. 모형 집합을 생성한다

   - 모형을 만들기 위해 사용된 데이터 집합 = 모형 집합
   - 모형 집합 (N X M) 으로 이루어져 있음
   - 균형 표본의 생성을 할 때도 있음
     - 만일 목표변수가 범주형일 경우, 범주형 변수의 각 클래스의 분포 비율이 불균형을 이룰 때가 있음, 이럴 때는 균형을 이루기 위해서 오버 샘플링, 언더 샘플링, 가중치 등등의 방법이 있음
   - 예측 모형을 만들 때는, (다음 달 매출액) 이번 달 매출액이 아니라 그 전달들의 매출액으로부터 예측 모형을 만들어야 한다.
   - 모형을 만들 때, 모형 집합을 훈련 집합, 검증 집합, 테스트 집합으로 나눈다.

5. 데이터의 문제들을 수정한다.

   - 수집한 데이터는 좋은 질을 유지하고 있지 않다. 따라서 정제해야만 한다.
   - 너무 많은 값을 가진 변수는 의미없는 변수들을 의미있는 변수로 변환할줄 알아야 한다.
   - 이상치, NULL 값 처리와 데이터 분포를 변환시키는 작업 등등을 해야 한다.
   - 시간에 따라 의미가 변하는 값
     - 신용 등급 "A" -> 과거와 현재의 데이터가 의미가 달라지는 경우 그것들을 매칭시켜주는 작업도 필요하다.
     - 일관성 없는 데이터를 일관성 있게 바꿔야 한다.

6. 정보가 드러나도록 데이터를 변환시킨다.

   - 변수를 변환시키는 단계

7. 모형들을 생성한다.

   - 방향성 데이터마이닝 (지도)
   - 무방향성 데이터마이닝 (비지도)

8. 모형들을 평가한다.

   - Confusion matrix

   - 정확도, 민감도, 재현율, 특이도 등등

   - 민감도와 재현율의 조화평균은 F1-SCORE

   - 리포트 차트를 사용한 이진 응답 모형의 평가

     - 이익도표(Gain Chart), 향상도 곡선(lift)

     

     

9. 모형들을 평가한다(2)

   - Regressor 평가
   - MAE, RMSE, MAPE

10. 모형들을 배치한다.

11. 처음부터 다시 시작한다.

    

<HR>



### 의사결정나무와 랜덤포레스트



##### 의사결정나무



분류를 위한 의사결정나무



- 의사결정나무 도식화(그림)
- 의사결정나무 점수화(Scoring)



회귀를 위한 의사결정나무



의사결정나무는 local 적이다. (전역)



##### 의사결정나무 생성 과정



1. 목표변수 순수도가 높게끔 가지치키 한다.
2. 타겟변수의 순수도가 높게끔 하는 입력변수가 무엇인지 선정
3. 계속 선정 -> 따라서 `순환적 알고리즘` 이라고 부름
4. Full Tree 계속 분리를 한 것. (최고의 모델이 아님)



##### 순수도



순수도가 높게끔 분기를 한다.



1. 0 ~ 1 사이의 값을  가지고 있음, 1일수록 순수하다고 이야기한다.
2. 범주형 변수 : 순수도를 평가하는 평가척도  지니, 엔트로피, 정보 이익 비율, 카이제곱 검정

3. 수치형 목표 변수 : 분산의 감소, F검정



여려 순수 척도 중, 지니 척도



지니 지수: 모집단에서 2개를 뽑았을 때, 그 2개가 같은 클래스에 속할 확률

EX) 주머니에 검은 돌 5개 흰돌 5개 있으면, 두 개 뽑았을 때 같은 클래스에 속할 확률은 흰돌 연속 두번이거나 검은돌 연속 두번임, 두 경우의 확률을 구하고 더하면 0.5임

1/2 * 1/2 = 1/4, 1/4 * 2 = 1/2





##### Full Tree



순수도를 기준으로 계속 나누게 되면 full tree 가 된다. 

하지만 훈련데이터에 너무 맞추어서 훈련을 하게 되면 실제 데이터를 잘 예측할 수 없는 과대적합 문제가 발생한다.



따라서 가지치기 필요하다.



##### 가지치기 알고리즘



가지치기 알고리즘 유명한 CART



CART 알고리즘



순수도 척도로 분할

BINARY SPLIT

알파와 같은 제약을 넣어서 제어한다.

검증용 데이터를 통해서 가치지기



C5.0 가지치기 알고리즘



순수도 척도로 분할

MULTIPLE SPLIT

비관적 가지치기 방법





##### SVM (Support vector machine)



두 개의 클래스를 구분할 수 있는 초평면을 구하기



초평면이 안만들어지는 경우도 있기 때문에 

kernal function -> 차원 높이고 초평면을 구하기



<hr>



### 앙상블 학습 유형



보팅 배깅, 부스팅





배깅 : 부트스트래핑 이용한 데이터 표본 이용

부스팅 : 여러 개의 약한 학습기를 순차적으로 학습-예측, 틀린 것에 가중치를 줘서 오류를 개선하기.



-GBM 방식



디시전트리 -> 디시전트리 오차에 대한 디시전트리 -> 또 그 오차에 대한 디시전트리



-Xgboost 와 LightGBM



